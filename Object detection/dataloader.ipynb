{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataloader.ipynb","provenance":[{"file_id":"1gvzspp_USPp81yXajgZvROOhRYFON4kg","timestamp":1602226105408}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JWT7h_6ZK_Ad"},"source":["from __future__ import print_function, division\n","import sys\n","import os\n","import torch\n","import numpy as np\n","import random\n","import csv\n","from pathlib import Path\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","from torch.utils.data.sampler import Sampler\n","\n","import skimage.io\n","import skimage.transform\n","import skimage.color\n","import skimage\n","\n","from PIL import Image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yz23TmPBLNXT"},"source":["class CSVDataset(Dataset):\n","    \"\"\"CSV dataset.\"\"\"\n","\n","    def __init__(self, img_path, train_file, class_list, transform=None):\n","\n","        self.img_path = img_path\n","        self.train_file = train_file\n","        self.class_list = class_list\n","        self.transform = transform\n","\n","        with self._open_for_csv(self.class_list) as file:\n","            self.classes = self.load_classes(csv.reader(file, delimiter=','))\n","            # {'word': 0}\n","\n","        self.labels = {}\n","        for key, value in self.classes.items():\n","            self.labels[value] = key\n","            # word\n","\n","        # csv with img_path, x1, y1, x2, y2, class_name\n","        self.image_data = {}  # error!!\n","        for file in self.train_file:\n","            with self._open_for_csv(file) as f:\n","                self.image_data.update(self._read_annotations(csv.reader(f, delimiter=','), self.classes))\n","\n","        self.image_names = list(self.image_data.keys())\n","        \n","\n","    def _parse(self, value, function, fmt):\n","        \"\"\"\n","        Parse a string into a value, and format a nice ValueError if it fails.\n","        Returns `function(value)`.\n","        Any `ValueError` raised is catched and a new `ValueError` is raised\n","        with message `fmt.format(e)`, where `e` is the caught `ValueError`.\n","        \"\"\"\n","        try:\n","            return function(value)\n","        except ValueError as e:\n","            raise_from(ValueError(fmt.format(e)), None)\n","\n","    def _open_for_csv(self, path):\n","        \"\"\"\n","        Open a file with flags suitable for csv.reader.\n","        This is different for python2 it means with mode 'rb',\n","        for python3 this means 'r' with \"universal newlines\".\n","        \"\"\"\n","        if sys.version_info[0] < 3:\n","            return open(path, 'rb')\n","        else:\n","            return open(path, 'r', newline='')\n","\n","    def load_classes(self, csv_reader):\n","        result = {}\n","\n","        for line, row in enumerate(csv_reader):\n","            line += 1\n","\n","            try:\n","                class_name, class_id = row\n","            except ValueError:\n","                raise(ValueError('line {}: format should be \\'class_name,class_id\\''.format(line)))\n","            class_id = self._parse(class_id, int, 'line {}: malformed class ID: {{}}'.format(line))\n","\n","            if class_name in result:\n","                raise ValueError('line {}: duplicate class name: \\'{}\\''.format(line, class_name))\n","            result[class_name] = class_id\n","        return result\n","\n","    def __len__(self):\n","        return len(self.image_names)\n","\n","    def __getitem__(self, idx):\n","\n","        img = self.load_image(idx)\n","        annot = self.load_annotations(idx)\n","        sample = {'img': img, 'annot': annot}\n","        if self.transform:\n","            sample = self.transform(sample)\n","\n","        return sample\n","\n","    def load_image(self, image_index):\n","        img_path = self.img_path #\"data_test\"\n","        img_name = os.path.join(img_path, self.image_names[image_index])\n","        img = skimage.io.imread(img_name)\n","\n","        if len(img.shape) == 2:\n","            img = skimage.color.gray2rgb(img)\n","\n","        return img.astype(np.float32)/255.0\n","\n","    def load_annotations(self, image_index):\n","        # get ground truth annotations\n","        annotation_list = self.image_data[self.image_names[image_index]]\n","        annotations     = np.zeros((0, 5))\n","\n","        # some images appear to miss annotations (like image with id 257034)\n","        if len(annotation_list) == 0:\n","            return annotations\n","\n","        # parse annotations\n","        for idx, a in enumerate(annotation_list):\n","            # some annotations have basically no width / height, skip them\n","            x1 = a['x1']\n","            x2 = a['x2']\n","            y1 = a['y1']\n","            y2 = a['y2']\n","\n","            if (x2-x1) < 1 or (y2-y1) < 1:\n","                continue\n","\n","            annotation        = np.zeros((1, 5))\n","            \n","            annotation[0, 0] = x1\n","            annotation[0, 1] = y1\n","            annotation[0, 2] = x2\n","            annotation[0, 3] = y2\n","\n","            annotation[0, 4]  = self.name_to_label(a['class'])\n","            annotations       = np.append(annotations, annotation, axis=0)\n","\n","        return annotations\n","\n","    def _read_annotations(self, csv_reader, classes):\n","        result = {}\n","        for line, row in enumerate(csv_reader):\n","            line += 1\n","\n","            try:\n","                img_file, x1, y1, x2, y2, class_name = row[:6]\n","            except ValueError:\n","                raise_from(ValueError('line {}: format should be \\'img_file,x1,y1,x2,y2,class_name\\' or \\'img_file,,,,,\\''.format(line)), None)\n","\n","            if img_file not in result:\n","                result[img_file] = []\n","\n","            # If a row contains only an image path, it's an image without annotations.\n","            if (x1, y1, x2, y2, class_name) == ('', '', '', '', ''):\n","                continue\n","\n","            x1 = self._parse(x1, int, 'line {}: malformed x1: {{}}'.format(line))\n","            y1 = self._parse(y1, int, 'line {}: malformed y1: {{}}'.format(line))\n","            x2 = self._parse(x2, int, 'line {}: malformed x2: {{}}'.format(line))\n","            y2 = self._parse(y2, int, 'line {}: malformed y2: {{}}'.format(line))\n","\n","            # Check that the bounding box is valid.\n","            if x2 <= x1:\n","                raise ValueError('line {}: x2 ({}) must be higher than x1 ({})'.format(line, x2, x1))\n","            if y2 <= y1:\n","                raise ValueError('line {}: y2 ({}) must be higher than y1 ({})'.format(line, y2, y1))\n","\n","            # check if the current class name is correctly present\n","            if class_name not in classes:\n","                raise ValueError('line {}: unknown class name: \\'{}\\' (classes: {})'.format(line, class_name, classes))\n","\n","            result[img_file].append({'x1': x1, 'x2': x2, 'y1': y1, 'y2': y2, 'class': class_name})\n","        return result\n","\n","    def name_to_label(self, name):\n","        return self.classes[name]\n","\n","    def label_to_name(self, label):\n","        return self.labels[label]\n","\n","    def num_classes(self):\n","        return max(self.classes.values()) + 1\n","\n","    def image_aspect_ratio(self, image_index):\n","        img_path = self.img_path\n","        img_name = os.path.join(img_path, self.image_names[image_index])\n","\n","        image = Image.open(img_name)\n","        return float(image.width) / float(image.height)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6wvRMwVnLO56"},"source":["def collater(data):\n","\n","    imgs = [s['img'] for s in data]\n","    annots = [s['annot'] for s in data]\n","    scales = [s['scale'] for s in data]\n","        \n","    widths = [int(s.shape[0]) for s in imgs]\n","    heights = [int(s.shape[1]) for s in imgs]\n","    batch_size = len(imgs)\n","\n","    max_width = np.array(widths).max()\n","    max_height = np.array(heights).max()\n","\n","    padded_imgs = torch.zeros(batch_size, max_width, max_height, 3)\n","\n","    for i in range(batch_size):\n","        img = imgs[i]\n","        padded_imgs[i, :int(img.shape[0]), :int(img.shape[1]), :] = img\n","\n","    max_num_annots = max(annot.shape[0] for annot in annots)\n","    \n","    if max_num_annots > 0:\n","\n","        annot_padded = torch.ones((len(annots), max_num_annots, 5)) * -1\n","\n","        if max_num_annots > 0:\n","            for idx, annot in enumerate(annots):\n","                #print(annot.shape)\n","                if annot.shape[0] > 0:\n","                    annot_padded[idx, :annot.shape[0], :] = annot\n","    else:\n","        annot_padded = torch.ones((len(annots), 1, 5)) * -1\n","\n","\n","    padded_imgs = padded_imgs.permute(0, 3, 1, 2)\n","\n","    return {'img': padded_imgs, 'annot': annot_padded, 'scale': scales}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahH6cKUrLUX5"},"source":["class Resizer(object):\n","    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n","\n","    def __call__(self, sample, min_side=608, max_side=1024):\n","        image, annots = sample['img'], sample['annot']\n","\n","        rows, cols, cns = image.shape\n","\n","        smallest_side = min(rows, cols)\n","\n","        # rescale the image so the smallest side is min_side\n","        scale = min_side / smallest_side\n","\n","        # check if the largest side is now greater than max_side, which can happen\n","        # when images have a large aspect ratio\n","        largest_side = max(rows, cols)\n","\n","        if largest_side * scale > max_side:\n","            scale = max_side / largest_side\n","\n","        # resize the image with the computed scale\n","        image = skimage.transform.resize(image, (int(round(rows*scale)), int(round((cols*scale)))))\n","        rows, cols, cns = image.shape\n","\n","        pad_w = 32 - rows%32\n","        pad_h = 32 - cols%32\n","\n","        new_image = np.zeros((rows + pad_w, cols + pad_h, cns)).astype(np.float32)\n","        new_image[:rows, :cols, :] = image.astype(np.float32)\n","\n","        annots[:, :4] *= scale\n","\n","        return {'img': torch.from_numpy(new_image), 'annot': torch.from_numpy(annots), 'scale': scale}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IJwW1_CVXuTX"},"source":["class Resizer2(object):\n","    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n","\n","    def __call__(self, sample, min_side=608, max_side=1024):\n","        \n","        multi_x = np.random.randint(low=6, high=11)/10\n","\n","        min_side, max_side = min_side*multi_x, max_side*multi_x\n","        \n","        image, annots = sample['img'], sample['annot']\n","\n","        rows, cols, cns = image.shape\n","\n","        smallest_side = min(rows, cols)\n","\n","        # rescale the image so the smallest side is min_side\n","        scale = min_side / smallest_side\n","\n","        # check if the largest side is now greater than max_side, which can happen\n","        # when images have a large aspect ratio\n","        largest_side = max(rows, cols)\n","\n","        if largest_side * scale > max_side:\n","            scale = max_side / largest_side\n","\n","        # resize the image with the computed scale\n","        image = skimage.transform.resize(image, (int(round(rows*scale)), int(round((cols*scale)))))\n","        rows, cols, cns = image.shape\n","\n","        pad_w = 32 - rows%32\n","        pad_h = 32 - cols%32\n","\n","        new_image = np.zeros((rows + pad_w, cols + pad_h, cns)).astype(np.float32)\n","        new_image[:rows, :cols, :] = image.astype(np.float32)\n","\n","        annots[:, :4] *= scale\n","\n","        return {'img': torch.from_numpy(new_image), 'annot': torch.from_numpy(annots), 'scale': scale}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T9PpUwW0LW1Z"},"source":["class Augmenter(object):\n","    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n","\n","    def __call__(self, sample, flip_x=0.5, prob=0.3):\n","\n","        if np.random.rand() < flip_x:\n","            image, annots = sample['img'], sample['annot']\n","            image = image[:, ::-1, :]\n","\n","            rows, cols, channels = image.shape\n","\n","            x1 = annots[:, 0].copy()\n","            x2 = annots[:, 2].copy()\n","            \n","            x_tmp = x1.copy()\n","\n","            annots[:, 0] = cols - x2\n","            annots[:, 2] = cols - x_tmp\n","\n","            sample = {'img': image, 'annot': annots}\n","\n","        return sample\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GWhuYBMOLX6Z"},"source":["class Normalizer(object):\n","\n","    def __init__(self):\n","        self.mean = np.array([[[0.485, 0.456, 0.406]]])\n","        self.std = np.array([[[0.229, 0.224, 0.225]]])\n","\n","    def __call__(self, sample):\n","\n","        image, annots = sample['img'], sample['annot']\n","\n","        return {'img':((image.astype(np.float32)-self.mean)/self.std), 'annot': annots}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7EKlPxUSLY3K"},"source":["class UnNormalizer(object):\n","    def __init__(self, mean=None, std=None):\n","        if mean == None:\n","            self.mean = [0.485, 0.456, 0.406]\n","        else:\n","            self.mean = mean\n","        if std == None:\n","            self.std = [0.229, 0.224, 0.225]\n","        else:\n","            self.std = std\n","\n","    def __call__(self, tensor):\n","        \"\"\"\n","        Args:\n","            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n","        Returns:\n","            Tensor: Normalized image.\n","        \"\"\"\n","        for t, m, s in zip(tensor, self.mean, self.std):\n","            t.mul_(s).add_(m)\n","        return tensor\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OpuFN9QsLZ2i"},"source":["class AspectRatioBasedSampler(Sampler):\n","\n","    def __init__(self, data_source, batch_size, drop_last):\n","        self.data_source = data_source\n","        self.batch_size = batch_size\n","        self.drop_last = drop_last\n","        self.groups = self.group_images()\n","\n","    def __iter__(self):\n","        random.shuffle(self.groups)\n","        for group in self.groups:\n","            yield group\n","\n","    def __len__(self):\n","        if self.drop_last:\n","            return len(self.data_source) // self.batch_size\n","        else:\n","            return (len(self.data_source) + self.batch_size - 1) // self.batch_size\n","\n","    def group_images(self):\n","        # determine the order of the images\n","        order = list(range(len(self.data_source)))\n","        order.sort(key=lambda x: self.data_source.image_aspect_ratio(x))\n","\n","        # divide into groups, one group = one batch\n","        return [[order[x % len(order)] for x in range(i, i + self.batch_size)] for i in range(0, len(order), self.batch_size)]\n"],"execution_count":null,"outputs":[]}]}